{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Google Analytics Forecasting.v1.1share",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saurabh231088/FBEVAL/blob/master/Google_Analytics_Forecasting_v1_1share.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "9E1nB_64XVrB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Website Traffic Prediction With Colaboratory and Facebook Prophet\n",
        "\n",
        "A few resources to read up on Prophet:\n",
        "\n",
        "\n",
        "*   https://research.fb.com/prophet-forecasting-at-scale/\n",
        "*   https://facebook.github.io/prophet/\n",
        "*   http://pbpython.com/prophet-overview.html\n",
        "\n",
        "At its core, the Prophet procedure is an additive regression model with four main components:\n",
        "\n",
        "*   A piecewise linear or logistic growth curve trend. Prophet automatically detects changes in trends by selecting changepoints from the data.\n",
        "*   A yearly seasonal component modeled using Fourier series.\n",
        "*   A weekly seasonal component using dummy variables.\n",
        "*   A user-provided list of important holidays.\n",
        "\n",
        "This notebook adds historical and future major holiday data, Google algorithm update history (Moz), as well as tools for getting and plotting Google Analytics data forecasts.\n",
        "\n",
        "**Note**: Works best in Google Chrome.  Some feature like downloading CSVs do not seem to work in other browsers.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "uO1_jr9BYRtD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Install needed libraries In Colab\n",
        "This will attempt to install Facebook Phophet, a requirent pystan, and a custom Google Analytics library updated to run on Colaboratory.\n"
      ]
    },
    {
      "metadata": {
        "id": "vE4vmaOFW41s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Install Libraries (This may need to be done first each time the notebook is used here.  Takes a few minutes to install)\n",
        "from IPython.display import clear_output\n",
        "try:\n",
        "  !pip install pystan\n",
        "  !pip install --upgrade git+https://github.com/jroakes/google-analytics.git\n",
        "  !pip install fbprophet\n",
        "except:\n",
        "  pass\n",
        "finally:\n",
        "  clear_output()\n",
        "  print('All Loaded')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CvIk0Qb4wG_N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Upload some datapoint files\n",
        "This makes available some helper functions, prior algorithm update dates (from Moz), and bank holiday dates through 2020.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "qXih3tPEwQAm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os.path\n",
        "\n",
        "if not os.path.isfile('holidays.csv'):\n",
        "  !wget https://raw.githubusercontent.com/jroakes/google-analytics/master/examples/holidays.csv\n",
        "if not os.path.isfile('algo_updates.csv'):\n",
        "  !wget https://raw.githubusercontent.com/jroakes/google-analytics/master/examples/algo_updates.csv\n",
        "if not os.path.isfile('helpers.py'):\n",
        "  !wget https://raw.githubusercontent.com/jroakes/google-analytics/master/examples/helpers.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qlqH0J2hYb48",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import needed libraries and add settings\n",
        "Imports needed libraries.  Also updates some settings needed to make this run more smoothly.\n",
        "\n",
        "**NOTE**: This includes limited Analytics API credentials.  Please do not share.  If you copy, pleas update the credentials to your own.\n",
        "\n",
        "**NOTE**: If you see errors the first run, try running again (or two times). I think this may be a pip/colab issue and not one with this code.\n"
      ]
    },
    {
      "metadata": {
        "id": "4nB4v7InXLXd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from fbprophet import Prophet\n",
        "import googleanalytics as ga\n",
        "import datetime\n",
        "import warnings\n",
        "import logging\n",
        "from helpers import Struct, get_months, print_profiles\n",
        "from google.colab import files\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from IPython.core.display import display, HTML, clear_output\n",
        "\n",
        "# Settings\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.CRITICAL)\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "%matplotlib inline\n",
        "plt.style.use('seaborn-colorblind')\n",
        "plt.rcParams['figure.figsize'] = 8.4, 6.8\n",
        "\n",
        "\n",
        "identity = \"analytics_access\"\n",
        "client_id = \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX.apps.googleusercontent.com\"\n",
        "client_secret = \"XXXXXXXXXXXXXXXXXXXXXXX\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c1n8Mv2pYqt2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Let's collect some data\n",
        "\n",
        "Here you will need to select the Account, Web Property, and Profile from your Google Analytics account (Names, not IDs) Then either enter Historical Data as a specific range, or Months Prior.  If Months Prior is greater than zero(0), it will be used, otherwise Specific Range will attempt to be used. Finally, select how many future months you want to predict, and enter the maximum daily volume (max_available_volume) possible for your specific niche (think amazon.com vs. joeshardware.com). If maximum volume is zero(0), linear growth will be used, else logistic. You can also specify to omit daily values (omit_values_over) above a certain threshold to remove outlier days where traffic spiked, but was a one-off occurance. \n",
        "\n",
        "If save output is \"yes\", a csv will be downloaded when the model is run.  You can use this for ad-hoc plotting in Excel.\n"
      ]
    },
    {
      "metadata": {
        "id": "feW_lcd8Ypj4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Google Analytics { run: \"auto\", form-width: \"50%\", display-mode: \"form\" }\n",
        "ga_account = \"\" #@param {type:\"string\"}\n",
        "ga_webproperty = \"\" #@param {type:\"string\"}\n",
        "ga_profile = \"\" #@param {type:\"string\"}\n",
        "ga_segment = \"organic traffic\" #@param [\"all users\", \"organic traffic\", \"direct traffic\", \"referral traffic\", \"mobile traffic\", \"tablet traffic\"] {type:\"string\"}\n",
        "ga_metric = \"sessions\" #@param [\"sessions\", \"pageviews\", \"unique pageviews\", \"transactions\"] {type:\"string\"}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oyL7FbO6dtjt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Historical Data (Specific Range) { run: \"auto\", form-width: \"50%\", display-mode: \"form\" }\n",
        "ga_start_date = \"2016-03-10\" #@param {type:\"date\"}\n",
        "ga_end_date = \"2018-03-10\" #@param {type:\"date\",name:\"GA Date\"}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CeR0INsHgdCE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Historical Data (Months Prior) { run: \"auto\", form-width: \"50%\", display-mode: \"form\" }\n",
        "prior_months = 36 #@param {type:\"integer\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9wDKYXT4eQib",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Prediction Data { run: \"auto\", form-width: \"50%\", display-mode: \"form\" }\n",
        "\n",
        "future_months = 12 #@param {type:\"integer\"}\n",
        "max_available_volume = 0  #@param {type:\"integer\"}\n",
        "omit_values_over = 400 #@param {type:\"integer\"}\n",
        "save_output = \"no\" #@param [\"yes\", \"no\"] {type:\"string\"}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VdwD5Twx1H0O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Authenticate\n",
        "This will produce a Authentication url that you must click and follow to authorize access to your gmail account.  The gmail account you choose should be the one with access to the property you want to analyze."
      ]
    },
    {
      "metadata": {
        "id": "NobuR4k7u_P3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "try:\n",
        "  profile = ga.authenticate(\n",
        "      client_id=client_id, \n",
        "      client_secret=client_secret, \n",
        "      identity=identity, \n",
        "      account=ga_account.strip(),\n",
        "      webproperty=ga_webproperty.strip(),\n",
        "      profile=ga_profile.strip(),     \n",
        "      interactive=True\n",
        "  )\n",
        "except Exception as e:\n",
        "  print('An error occured', str(e))\n",
        "\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2iY9LNC9g5vT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Run The Models"
      ]
    },
    {
      "metadata": {
        "id": "HuSDNmS6cUEH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load needed functions\n",
        "These are only functions that we need to make available to python to run the models.  There are settings in the run_model function that can updated for your specific use case.  The run_model function handles most of the heavy lifting with the prediction."
      ]
    },
    {
      "metadata": {
        "id": "_vwpGEOJRMSG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def get_ga_data(profile, data ):\n",
        "\n",
        "  try:\n",
        "    if data.prior_months and int(data.prior_months) > 0:\n",
        "      sessions = profile.core.query.metrics(data.ga_metric).segment(data.ga_segment).daily(months=(0-int(data.prior_months) )).report\n",
        "    else:\n",
        "      sessions = profile.core.query.metrics(data.ga_metric).segment(data.ga_segment).daily(data.ga_start_date,data.ga_end_date ).report\n",
        "  except Exception as e:\n",
        "    print('Error. Error retreiving data from Google Analytics.', str(e))\n",
        "\n",
        "  df = sessions.as_dataframe()\n",
        "  \n",
        "  df['date'] = pd.to_datetime(df['date'])\n",
        "  \n",
        "  return df\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "def run_model(df, data):\n",
        "  \n",
        "  max_daily = df[data.ga_metric].max()\n",
        "  \n",
        "  # Remove zero values\n",
        "  df.loc[(df[data.ga_metric] < 1 ), data.ga_metric] = np.nan\n",
        "  \n",
        "  if data.prior_months and int(data.prior_months) > 0:\n",
        "    prior = data.prior_months\n",
        "    end_historical = datetime.date.today().strftime(\"%Y-%m-%d\")\n",
        "  else:\n",
        "    prior = get_months(data.ga_start_date,data.ga_end_date )\n",
        "    end_historical = data.ga_end_date\n",
        "    \n",
        "\n",
        "  if data.omit_values_over and int(data.omit_values_over) > 0:\n",
        "    df.loc[(df[data.ga_metric] > data.omit_values_over), data.ga_metric] = np.nan\n",
        "      \n",
        "  if df[data.ga_metric].isnull().all():\n",
        "    print(\"Error: omit_values_over is set to {} and the largest daily {} value is {}\".format(str(data.omit_values_over),str(data.ga_metric), str(max_daily) ))\n",
        "    return False, False\n",
        "    \n",
        "  # Take a look at a plot of the data\n",
        "  df.set_index('date').plot(title=\"{}-month {} for {}\".format(str(prior),data.ga_metric, data.ga_webproperty))\n",
        "\n",
        "  # Convert traffic to a log value to understand the data's behavior linearly. \n",
        "  df[data.ga_metric] = np.log(df[data.ga_metric])\n",
        "\n",
        "  # For the Prophet API, rename Day Index and Sessions to ds and y\n",
        "  df.columns = ['ds', 'y']\n",
        "\n",
        "  if data.max_available_volume and data.max_available_volume > 0:      \n",
        "    # Add Cap\n",
        "    df['cap'] = np.log(data.max_available_volume)\n",
        "    growth = \"logistic\"\n",
        "  else:\n",
        "    growth = \"linear\"\n",
        "    \n",
        "  \n",
        "  # Loading algorithm and holiday information\n",
        "  al_df = pd.read_csv('algo_updates.csv')\n",
        "  hol_df = pd.read_csv('holidays.csv')\n",
        "  \n",
        "  al_dates = pd.to_datetime(al_df['date'].tolist())\n",
        "  hol_dates = pd.to_datetime(hol_df['date'].tolist())\n",
        "    \n",
        "  # Bank Holidays  \n",
        "  c1 = pd.DataFrame({\n",
        "    'holiday': 'bank_holidays',\n",
        "    'ds': hol_dates,\n",
        "    'prior_scale': 1,\n",
        "    'lower_window': -5,\n",
        "    'upper_window': 5,\n",
        "  })\n",
        "  \n",
        "  # Algorithm Updates  \n",
        "  c2 = pd.DataFrame({\n",
        "    'holiday': 'prior_algorithm_updates',\n",
        "    'ds': al_dates,\n",
        "    'prior_scale':5,\n",
        "    'lower_window': 0,\n",
        "    'upper_window': 10,\n",
        "  })\n",
        "\n",
        "  calendar = pd.concat([c1,c2])\n",
        "\n",
        "  # Fit the model to the data\n",
        "  model = Prophet(growth = growth, holidays=calendar)\n",
        "  model.fit(df)\n",
        "\n",
        "  # Define how far in the future for Prophet to predict\n",
        "  future = model.make_future_dataframe(periods=int(data.future_months*30.42))\n",
        "\n",
        "  if data.max_available_volume and data.max_available_volume > 0: \n",
        "    future['cap'] = np.log(data.max_available_volume)\n",
        "\n",
        "  # Apply predict\n",
        "  forecast = model.predict(future)\n",
        "  \n",
        "  # Bring back from log space.\n",
        "  trns_cols = [ 'trend', 'trend_lower', 'trend_upper', 'yhat_lower', 'yhat_upper', 'yhat']\n",
        "  forecast[trns_cols] = np.exp(forecast[trns_cols]).round()\n",
        "  model.history['y'] = np.exp(model.history['y']).round()\n",
        "  \n",
        "  model.plot(forecast, xlabel='date', ylabel=ga_metric)\n",
        "  \n",
        "  model.plot_components(forecast)\n",
        "\n",
        "  return model, forecast"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Eq0JlSgEcZU3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Run\n",
        "This cell will output:\n",
        "\n",
        "\n",
        "*   Plot of prior Analytics data in your specific metric.\n",
        "*   Plot of output of the forecast (including prior data) log transformed.\n",
        "*   Plot of output of the forecast (including prior data) converted back to your original metric.\n",
        "*   Plots of component parts of the forcast including holidays and weekly / yearly trends.\n",
        "\n",
        "If save_output is \"yes\", a csv of the forecast data will attempt to be downloaded.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "GeixUCAFW-Rz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = {\n",
        "        'ga_account': ga_account,\n",
        "        'ga_webproperty': ga_webproperty,\n",
        "        'ga_segment': ga_segment,\n",
        "        'ga_metric': ga_metric,\n",
        "        'ga_start_date': ga_start_date,\n",
        "        'ga_end_date': ga_end_date,\n",
        "        'prior_months': prior_months,\n",
        "    \n",
        "        'future_months': future_months,\n",
        "        'max_available_volume': max_available_volume,\n",
        "        'omit_values_over': omit_values_over\n",
        "        }\n",
        "\n",
        "data = Struct(**data)\n",
        "\n",
        "# Get data from Analytics\n",
        "datafile = get_ga_data(profile, data)\n",
        "\n",
        "\n",
        "# Create Model and get forecast\n",
        "model, forecast = run_model(datafile, data)\n",
        "\n",
        "# Maybe save output\n",
        "if save_output == 'yes':\n",
        "  forecast.to_csv('forecast.csv')\n",
        "  files.download('forecast.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}